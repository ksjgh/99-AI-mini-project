{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_LSTM_basic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJXZFc4CN47m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# see https://youtu.be/iMIWee_PXl8\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVrGv0Gnxh02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data = [[ [(j+i)] for i in range(5)] for j in range(100) ]\n",
        "data = [[ [(j+i)/100] for i in range(5)] for j in range(100) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyMax_TyyCJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f612cde5-123f-4cc3-88cc-b97837397fad"
      },
      "source": [
        "data[:10]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[0.0], [0.01], [0.02], [0.03], [0.04]],\n",
              " [[0.01], [0.02], [0.03], [0.04], [0.05]],\n",
              " [[0.02], [0.03], [0.04], [0.05], [0.06]],\n",
              " [[0.03], [0.04], [0.05], [0.06], [0.07]],\n",
              " [[0.04], [0.05], [0.06], [0.07], [0.08]],\n",
              " [[0.05], [0.06], [0.07], [0.08], [0.09]],\n",
              " [[0.06], [0.07], [0.08], [0.09], [0.1]],\n",
              " [[0.07], [0.08], [0.09], [0.1], [0.11]],\n",
              " [[0.08], [0.09], [0.1], [0.11], [0.12]],\n",
              " [[0.09], [0.1], [0.11], [0.12], [0.13]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWrn5BCGyE4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = [ (i+5)/100 for i in range(100) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68IX7Ix1yHsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db1bd2d7-7df0-4d89-f418-ff819789b57d"
      },
      "source": [
        "target[:10]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50z2ITr1GVCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test for variable sequence length\n",
        "# data = [[ [(j+i)/100] for i in range(5)] for j in range(100) ]\n",
        "# target = [ (i++5)/100 for i in range(100) ]\n",
        "\n",
        "data = [[ [(j+i)/100] for i in range(6)] for j in range(100) ]\n",
        "target = [ (i+6)/100 for i in range(100) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxuNb4yBydEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array(data,dtype=float)\n",
        "target = np.array(target,dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn2Diy60y-ap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee116d51-9f53-4e43-cfad-57398e744c65"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 6, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-CUxW1AzBGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e011329-d443-41ae-c9e2-00ed01b5f0cc"
      },
      "source": [
        "target.shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNjT1m9PzC0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train , x_test , y_train, y_test = train_test_split( data, target, test_size = 0.2, random_state=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yllMZNKczzMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyCJy7t11pJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.add( LSTM((1), batch_input_shape = (None,5,1), return_sequences=True) )\n",
        "model.add( LSTM((1), batch_input_shape = (None,None,1), return_sequences=True) )\n",
        "model.add( LSTM((1), return_sequences=False ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p397ZE3O1_nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"mean_absolute_error\", optimizer = \"adam\", metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWkI1s-Z2Y8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "21a29d83-ebcb-410c-b43d-5ff22117ec42"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_7 (LSTM)                (None, None, 1)           12        \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 1)                 12        \n",
            "=================================================================\n",
            "Total params: 24\n",
            "Trainable params: 24\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-WdxVm92bWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10234
        },
        "outputId": "050f8145-10f1-4b92-cc87-c4ed70ae3ba2"
      },
      "source": [
        "history = model.fit( x_train, y_train, epochs=300, validation_data=(x_test,y_test) )"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/300\n",
            "80/80 [==============================] - 0s 826us/step - loss: 0.0685 - acc: 0.0125 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
            "Epoch 2/300\n",
            "80/80 [==============================] - 0s 742us/step - loss: 0.0534 - acc: 0.0125 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
            "Epoch 3/300\n",
            "80/80 [==============================] - 0s 722us/step - loss: 0.0428 - acc: 0.0125 - val_loss: 0.0436 - val_acc: 0.0000e+00\n",
            "Epoch 4/300\n",
            "80/80 [==============================] - 0s 798us/step - loss: 0.0373 - acc: 0.0125 - val_loss: 0.0523 - val_acc: 0.0000e+00\n",
            "Epoch 5/300\n",
            "80/80 [==============================] - 0s 763us/step - loss: 0.0342 - acc: 0.0125 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
            "Epoch 6/300\n",
            "80/80 [==============================] - 0s 750us/step - loss: 0.0309 - acc: 0.0125 - val_loss: 0.0403 - val_acc: 0.0000e+00\n",
            "Epoch 7/300\n",
            "80/80 [==============================] - 0s 745us/step - loss: 0.0229 - acc: 0.0125 - val_loss: 0.0234 - val_acc: 0.0000e+00\n",
            "Epoch 8/300\n",
            "80/80 [==============================] - 0s 727us/step - loss: 0.0200 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 9/300\n",
            "80/80 [==============================] - 0s 727us/step - loss: 0.0201 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 10/300\n",
            "80/80 [==============================] - 0s 711us/step - loss: 0.0186 - acc: 0.0125 - val_loss: 0.0209 - val_acc: 0.0000e+00\n",
            "Epoch 11/300\n",
            "80/80 [==============================] - 0s 723us/step - loss: 0.0184 - acc: 0.0125 - val_loss: 0.0227 - val_acc: 0.0000e+00\n",
            "Epoch 12/300\n",
            "80/80 [==============================] - 0s 713us/step - loss: 0.0187 - acc: 0.0125 - val_loss: 0.0211 - val_acc: 0.0000e+00\n",
            "Epoch 13/300\n",
            "80/80 [==============================] - 0s 711us/step - loss: 0.0181 - acc: 0.0125 - val_loss: 0.0207 - val_acc: 0.0000e+00\n",
            "Epoch 14/300\n",
            "80/80 [==============================] - 0s 706us/step - loss: 0.0180 - acc: 0.0125 - val_loss: 0.0207 - val_acc: 0.0000e+00\n",
            "Epoch 15/300\n",
            "80/80 [==============================] - 0s 718us/step - loss: 0.0177 - acc: 0.0125 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
            "Epoch 16/300\n",
            "80/80 [==============================] - 0s 722us/step - loss: 0.0177 - acc: 0.0125 - val_loss: 0.0209 - val_acc: 0.0000e+00\n",
            "Epoch 17/300\n",
            "80/80 [==============================] - 0s 714us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0206 - val_acc: 0.0000e+00\n",
            "Epoch 18/300\n",
            "80/80 [==============================] - 0s 707us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 19/300\n",
            "80/80 [==============================] - 0s 722us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 20/300\n",
            "80/80 [==============================] - 0s 716us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
            "Epoch 21/300\n",
            "80/80 [==============================] - 0s 699us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0211 - val_acc: 0.0000e+00\n",
            "Epoch 22/300\n",
            "80/80 [==============================] - 0s 707us/step - loss: 0.0176 - acc: 0.0125 - val_loss: 0.0207 - val_acc: 0.0000e+00\n",
            "Epoch 23/300\n",
            "80/80 [==============================] - 0s 726us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 24/300\n",
            "80/80 [==============================] - 0s 738us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 25/300\n",
            "80/80 [==============================] - 0s 727us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 26/300\n",
            "80/80 [==============================] - 0s 745us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 27/300\n",
            "80/80 [==============================] - 0s 803us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 28/300\n",
            "80/80 [==============================] - 0s 732us/step - loss: 0.0173 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 29/300\n",
            "80/80 [==============================] - 0s 735us/step - loss: 0.0173 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 30/300\n",
            "80/80 [==============================] - 0s 746us/step - loss: 0.0173 - acc: 0.0125 - val_loss: 0.0206 - val_acc: 0.0000e+00\n",
            "Epoch 31/300\n",
            "80/80 [==============================] - 0s 692us/step - loss: 0.0173 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 32/300\n",
            "80/80 [==============================] - 0s 711us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 33/300\n",
            "80/80 [==============================] - 0s 677us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 34/300\n",
            "80/80 [==============================] - 0s 681us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 35/300\n",
            "80/80 [==============================] - 0s 706us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0206 - val_acc: 0.0000e+00\n",
            "Epoch 36/300\n",
            "80/80 [==============================] - 0s 680us/step - loss: 0.0173 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 37/300\n",
            "80/80 [==============================] - 0s 721us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 38/300\n",
            "80/80 [==============================] - 0s 707us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 39/300\n",
            "80/80 [==============================] - 0s 719us/step - loss: 0.0173 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 40/300\n",
            "80/80 [==============================] - 0s 790us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 41/300\n",
            "80/80 [==============================] - 0s 763us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 42/300\n",
            "80/80 [==============================] - 0s 761us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 43/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 44/300\n",
            "80/80 [==============================] - 0s 878us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 45/300\n",
            "80/80 [==============================] - 0s 771us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
            "Epoch 46/300\n",
            "80/80 [==============================] - 0s 792us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 47/300\n",
            "80/80 [==============================] - 0s 787us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 48/300\n",
            "80/80 [==============================] - 0s 769us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 49/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 50/300\n",
            "80/80 [==============================] - 0s 750us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
            "Epoch 51/300\n",
            "80/80 [==============================] - 0s 750us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0207 - val_acc: 0.0000e+00\n",
            "Epoch 52/300\n",
            "80/80 [==============================] - 0s 789us/step - loss: 0.0173 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 53/300\n",
            "80/80 [==============================] - 0s 785us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 54/300\n",
            "80/80 [==============================] - 0s 819us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 55/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 56/300\n",
            "80/80 [==============================] - 0s 774us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 57/300\n",
            "80/80 [==============================] - 0s 750us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 58/300\n",
            "80/80 [==============================] - 0s 765us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 59/300\n",
            "80/80 [==============================] - 0s 789us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 60/300\n",
            "80/80 [==============================] - 0s 900us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 61/300\n",
            "80/80 [==============================] - 0s 771us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0206 - val_acc: 0.0000e+00\n",
            "Epoch 62/300\n",
            "80/80 [==============================] - 0s 747us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 63/300\n",
            "80/80 [==============================] - 0s 781us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 64/300\n",
            "80/80 [==============================] - 0s 776us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 65/300\n",
            "80/80 [==============================] - 0s 770us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 66/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
            "Epoch 67/300\n",
            "80/80 [==============================] - 0s 781us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 68/300\n",
            "80/80 [==============================] - 0s 775us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 69/300\n",
            "80/80 [==============================] - 0s 769us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 70/300\n",
            "80/80 [==============================] - 0s 778us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 71/300\n",
            "80/80 [==============================] - 0s 774us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 72/300\n",
            "80/80 [==============================] - 0s 817us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 73/300\n",
            "80/80 [==============================] - 0s 765us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 74/300\n",
            "80/80 [==============================] - 0s 765us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 75/300\n",
            "80/80 [==============================] - 0s 768us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 76/300\n",
            "80/80 [==============================] - 0s 881us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 77/300\n",
            "80/80 [==============================] - 0s 775us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 78/300\n",
            "80/80 [==============================] - 0s 798us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
            "Epoch 79/300\n",
            "80/80 [==============================] - 0s 778us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 80/300\n",
            "80/80 [==============================] - 0s 760us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
            "Epoch 81/300\n",
            "80/80 [==============================] - 0s 765us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 82/300\n",
            "80/80 [==============================] - 0s 780us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
            "Epoch 83/300\n",
            "80/80 [==============================] - 0s 781us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 84/300\n",
            "80/80 [==============================] - 0s 772us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 85/300\n",
            "80/80 [==============================] - 0s 768us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 86/300\n",
            "80/80 [==============================] - 0s 759us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 87/300\n",
            "80/80 [==============================] - 0s 798us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 88/300\n",
            "80/80 [==============================] - 0s 796us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
            "Epoch 89/300\n",
            "80/80 [==============================] - 0s 791us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 90/300\n",
            "80/80 [==============================] - 0s 795us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 91/300\n",
            "80/80 [==============================] - 0s 759us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 92/300\n",
            "80/80 [==============================] - 0s 892us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 93/300\n",
            "80/80 [==============================] - 0s 801us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 94/300\n",
            "80/80 [==============================] - 0s 769us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 95/300\n",
            "80/80 [==============================] - 0s 778us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 96/300\n",
            "80/80 [==============================] - 0s 759us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 97/300\n",
            "80/80 [==============================] - 0s 755us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 98/300\n",
            "80/80 [==============================] - 0s 771us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 99/300\n",
            "80/80 [==============================] - 0s 775us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 100/300\n",
            "80/80 [==============================] - 0s 750us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 101/300\n",
            "80/80 [==============================] - 0s 752us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 102/300\n",
            "80/80 [==============================] - 0s 762us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 103/300\n",
            "80/80 [==============================] - 0s 775us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 104/300\n",
            "80/80 [==============================] - 0s 765us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 105/300\n",
            "80/80 [==============================] - 0s 766us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
            "Epoch 106/300\n",
            "80/80 [==============================] - 0s 781us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 107/300\n",
            "80/80 [==============================] - 0s 789us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 108/300\n",
            "80/80 [==============================] - 0s 850us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 109/300\n",
            "80/80 [==============================] - 0s 838us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 110/300\n",
            "80/80 [==============================] - 0s 783us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 111/300\n",
            "80/80 [==============================] - 0s 770us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 112/300\n",
            "80/80 [==============================] - 0s 749us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 113/300\n",
            "80/80 [==============================] - 0s 766us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 114/300\n",
            "80/80 [==============================] - 0s 793us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 115/300\n",
            "80/80 [==============================] - 0s 781us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 116/300\n",
            "80/80 [==============================] - 0s 779us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 117/300\n",
            "80/80 [==============================] - 0s 769us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 118/300\n",
            "80/80 [==============================] - 0s 760us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 119/300\n",
            "80/80 [==============================] - 0s 793us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 120/300\n",
            "80/80 [==============================] - 0s 791us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 121/300\n",
            "80/80 [==============================] - 0s 761us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 122/300\n",
            "80/80 [==============================] - 0s 779us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 123/300\n",
            "80/80 [==============================] - 0s 769us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 124/300\n",
            "80/80 [==============================] - 0s 768us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 125/300\n",
            "80/80 [==============================] - 0s 911us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 126/300\n",
            "80/80 [==============================] - 0s 791us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 127/300\n",
            "80/80 [==============================] - 0s 782us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 128/300\n",
            "80/80 [==============================] - 0s 748us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 129/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 130/300\n",
            "80/80 [==============================] - 0s 832us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 131/300\n",
            "80/80 [==============================] - 0s 781us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 132/300\n",
            "80/80 [==============================] - 0s 756us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 133/300\n",
            "80/80 [==============================] - 0s 753us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 134/300\n",
            "80/80 [==============================] - 0s 758us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 135/300\n",
            "80/80 [==============================] - 0s 786us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 136/300\n",
            "80/80 [==============================] - 0s 792us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 137/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 138/300\n",
            "80/80 [==============================] - 0s 759us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 139/300\n",
            "80/80 [==============================] - 0s 753us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 140/300\n",
            "80/80 [==============================] - 0s 758us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 141/300\n",
            "80/80 [==============================] - 0s 870us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 142/300\n",
            "80/80 [==============================] - 0s 784us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 143/300\n",
            "80/80 [==============================] - 0s 763us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 144/300\n",
            "80/80 [==============================] - 0s 764us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 145/300\n",
            "80/80 [==============================] - 0s 757us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 146/300\n",
            "80/80 [==============================] - 0s 774us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 147/300\n",
            "80/80 [==============================] - 0s 800us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 148/300\n",
            "80/80 [==============================] - 0s 752us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 149/300\n",
            "80/80 [==============================] - 0s 755us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 150/300\n",
            "80/80 [==============================] - 0s 764us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 151/300\n",
            "80/80 [==============================] - 0s 783us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 152/300\n",
            "80/80 [==============================] - 0s 765us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 153/300\n",
            "80/80 [==============================] - 0s 755us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 154/300\n",
            "80/80 [==============================] - 0s 800us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 155/300\n",
            "80/80 [==============================] - 0s 788us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 156/300\n",
            "80/80 [==============================] - 0s 773us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
            "Epoch 157/300\n",
            "80/80 [==============================] - 0s 883us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0206 - val_acc: 0.0000e+00\n",
            "Epoch 158/300\n",
            "80/80 [==============================] - 0s 779us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 159/300\n",
            "80/80 [==============================] - 0s 788us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 160/300\n",
            "80/80 [==============================] - 0s 800us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 161/300\n",
            "80/80 [==============================] - 0s 771us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 162/300\n",
            "80/80 [==============================] - 0s 783us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 163/300\n",
            "80/80 [==============================] - 0s 784us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 164/300\n",
            "80/80 [==============================] - 0s 773us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 165/300\n",
            "80/80 [==============================] - 0s 766us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 166/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 167/300\n",
            "80/80 [==============================] - 0s 774us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 168/300\n",
            "80/80 [==============================] - 0s 781us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 169/300\n",
            "80/80 [==============================] - 0s 793us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 170/300\n",
            "80/80 [==============================] - 0s 919us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 171/300\n",
            "80/80 [==============================] - 0s 786us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 172/300\n",
            "80/80 [==============================] - 0s 747us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 173/300\n",
            "80/80 [==============================] - 0s 897us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 174/300\n",
            "80/80 [==============================] - 0s 785us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
            "Epoch 175/300\n",
            "80/80 [==============================] - 0s 808us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 176/300\n",
            "80/80 [==============================] - 0s 819us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 177/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 178/300\n",
            "80/80 [==============================] - 0s 777us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 179/300\n",
            "80/80 [==============================] - 0s 778us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 180/300\n",
            "80/80 [==============================] - 0s 780us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 181/300\n",
            "80/80 [==============================] - 0s 780us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 182/300\n",
            "80/80 [==============================] - 0s 758us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 183/300\n",
            "80/80 [==============================] - 0s 766us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 184/300\n",
            "80/80 [==============================] - 0s 779us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 185/300\n",
            "80/80 [==============================] - 0s 789us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 186/300\n",
            "80/80 [==============================] - 0s 780us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 187/300\n",
            "80/80 [==============================] - 0s 756us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 188/300\n",
            "80/80 [==============================] - 0s 771us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 189/300\n",
            "80/80 [==============================] - 0s 880us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 190/300\n",
            "80/80 [==============================] - 0s 780us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 191/300\n",
            "80/80 [==============================] - 0s 785us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 192/300\n",
            "80/80 [==============================] - 0s 783us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 193/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 194/300\n",
            "80/80 [==============================] - 0s 782us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 195/300\n",
            "80/80 [==============================] - 0s 800us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
            "Epoch 196/300\n",
            "80/80 [==============================] - 0s 772us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 197/300\n",
            "80/80 [==============================] - 0s 783us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 198/300\n",
            "80/80 [==============================] - 0s 774us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 199/300\n",
            "80/80 [==============================] - 0s 772us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 200/300\n",
            "80/80 [==============================] - 0s 765us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 201/300\n",
            "80/80 [==============================] - 0s 769us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 202/300\n",
            "80/80 [==============================] - 0s 786us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 203/300\n",
            "80/80 [==============================] - 0s 798us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 204/300\n",
            "80/80 [==============================] - 0s 783us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 205/300\n",
            "80/80 [==============================] - 0s 855us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 206/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 207/300\n",
            "80/80 [==============================] - 0s 786us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 208/300\n",
            "80/80 [==============================] - 0s 780us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 209/300\n",
            "80/80 [==============================] - 0s 774us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 210/300\n",
            "80/80 [==============================] - 0s 762us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 211/300\n",
            "80/80 [==============================] - 0s 758us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 212/300\n",
            "80/80 [==============================] - 0s 769us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 213/300\n",
            "80/80 [==============================] - 0s 778us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 214/300\n",
            "80/80 [==============================] - 0s 764us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 215/300\n",
            "80/80 [==============================] - 0s 794us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 216/300\n",
            "80/80 [==============================] - 0s 799us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 217/300\n",
            "80/80 [==============================] - 0s 755us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 218/300\n",
            "80/80 [==============================] - 0s 769us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 219/300\n",
            "80/80 [==============================] - 0s 833us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 220/300\n",
            "80/80 [==============================] - 0s 766us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 221/300\n",
            "80/80 [==============================] - 0s 864us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 222/300\n",
            "80/80 [==============================] - 0s 804us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 223/300\n",
            "80/80 [==============================] - 0s 798us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 224/300\n",
            "80/80 [==============================] - 0s 795us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 225/300\n",
            "80/80 [==============================] - 0s 773us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 226/300\n",
            "80/80 [==============================] - 0s 753us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 227/300\n",
            "80/80 [==============================] - 0s 756us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 228/300\n",
            "80/80 [==============================] - 0s 762us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 229/300\n",
            "80/80 [==============================] - 0s 791us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
            "Epoch 230/300\n",
            "80/80 [==============================] - 0s 805us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
            "Epoch 231/300\n",
            "80/80 [==============================] - 0s 750us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 232/300\n",
            "80/80 [==============================] - 0s 770us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 233/300\n",
            "80/80 [==============================] - 0s 778us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 234/300\n",
            "80/80 [==============================] - 0s 796us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 235/300\n",
            "80/80 [==============================] - 0s 768us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
            "Epoch 236/300\n",
            "80/80 [==============================] - 0s 771us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 237/300\n",
            "80/80 [==============================] - 0s 848us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 238/300\n",
            "80/80 [==============================] - 0s 768us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 239/300\n",
            "80/80 [==============================] - 0s 773us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 240/300\n",
            "80/80 [==============================] - 0s 765us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 241/300\n",
            "80/80 [==============================] - 0s 762us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 242/300\n",
            "80/80 [==============================] - 0s 756us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 243/300\n",
            "80/80 [==============================] - 0s 760us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 244/300\n",
            "80/80 [==============================] - 0s 768us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 245/300\n",
            "80/80 [==============================] - 0s 773us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
            "Epoch 246/300\n",
            "80/80 [==============================] - 0s 779us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 247/300\n",
            "80/80 [==============================] - 0s 775us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 248/300\n",
            "80/80 [==============================] - 0s 777us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
            "Epoch 249/300\n",
            "80/80 [==============================] - 0s 768us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
            "Epoch 250/300\n",
            "80/80 [==============================] - 0s 797us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 251/300\n",
            "80/80 [==============================] - 0s 759us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 252/300\n",
            "80/80 [==============================] - 0s 800us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 253/300\n",
            "80/80 [==============================] - 0s 811us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 254/300\n",
            "80/80 [==============================] - 0s 832us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
            "Epoch 255/300\n",
            "80/80 [==============================] - 0s 785us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 256/300\n",
            "80/80 [==============================] - 0s 759us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
            "Epoch 257/300\n",
            "80/80 [==============================] - 0s 777us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
            "Epoch 258/300\n",
            "80/80 [==============================] - 0s 768us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 259/300\n",
            "80/80 [==============================] - 0s 751us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 260/300\n",
            "80/80 [==============================] - 0s 760us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 261/300\n",
            "80/80 [==============================] - 0s 771us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 262/300\n",
            "80/80 [==============================] - 0s 757us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 263/300\n",
            "80/80 [==============================] - 0s 777us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 264/300\n",
            "80/80 [==============================] - 0s 783us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 265/300\n",
            "80/80 [==============================] - 0s 750us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 266/300\n",
            "80/80 [==============================] - 0s 756us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 267/300\n",
            "80/80 [==============================] - 0s 757us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 268/300\n",
            "80/80 [==============================] - 0s 804us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 269/300\n",
            "80/80 [==============================] - 0s 776us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 270/300\n",
            "80/80 [==============================] - 0s 894us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 271/300\n",
            "80/80 [==============================] - 0s 750us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 272/300\n",
            "80/80 [==============================] - 0s 742us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 273/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 274/300\n",
            "80/80 [==============================] - 0s 788us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 275/300\n",
            "80/80 [==============================] - 0s 760us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 276/300\n",
            "80/80 [==============================] - 0s 764us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0185 - val_acc: 0.0000e+00\n",
            "Epoch 277/300\n",
            "80/80 [==============================] - 0s 775us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 278/300\n",
            "80/80 [==============================] - 0s 779us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 279/300\n",
            "80/80 [==============================] - 0s 804us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 280/300\n",
            "80/80 [==============================] - 0s 772us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
            "Epoch 281/300\n",
            "80/80 [==============================] - 0s 793us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0185 - val_acc: 0.0000e+00\n",
            "Epoch 282/300\n",
            "80/80 [==============================] - 0s 768us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 283/300\n",
            "80/80 [==============================] - 0s 769us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 284/300\n",
            "80/80 [==============================] - 0s 801us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 285/300\n",
            "80/80 [==============================] - 0s 771us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 286/300\n",
            "80/80 [==============================] - 0s 886us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 287/300\n",
            "80/80 [==============================] - 0s 770us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 288/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 289/300\n",
            "80/80 [==============================] - 0s 785us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 290/300\n",
            "80/80 [==============================] - 0s 783us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 291/300\n",
            "80/80 [==============================] - 0s 776us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 292/300\n",
            "80/80 [==============================] - 0s 767us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 293/300\n",
            "80/80 [==============================] - 0s 782us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 294/300\n",
            "80/80 [==============================] - 0s 771us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 295/300\n",
            "80/80 [==============================] - 0s 789us/step - loss: 0.0155 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 296/300\n",
            "80/80 [==============================] - 0s 785us/step - loss: 0.0155 - acc: 0.0125 - val_loss: 0.0191 - val_acc: 0.0000e+00\n",
            "Epoch 297/300\n",
            "80/80 [==============================] - 0s 781us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0190 - val_acc: 0.0000e+00\n",
            "Epoch 298/300\n",
            "80/80 [==============================] - 0s 757us/step - loss: 0.0155 - acc: 0.0125 - val_loss: 0.0185 - val_acc: 0.0000e+00\n",
            "Epoch 299/300\n",
            "80/80 [==============================] - 0s 786us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
            "Epoch 300/300\n",
            "80/80 [==============================] - 0s 776us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoWkBT_K3P8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_pred = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnw_frTh3hsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c63c0694-2a13-4b5c-d326-dd130a289add"
      },
      "source": [
        "plt.scatter( range(20), x_pred, c='r')\n",
        "plt.scatter( range(20), y_test, c='g')\n",
        "plt.show()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n52wrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTciX5Dd38V-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "455d1584-e14c-4452-f6bd-6805b946a9ef"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8u_HsNc4S4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c435ecc-4440-4d26-a7c1-190afc9c5622"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7CEh7fxGNnc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "386cabfd-4e9b-4471-a81b-2420eb175784"
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.show()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE3BJREFUeJzt3X+s3fV93/Hnq3bsjCVAY64ihklN\nhivqVl1BRygTVTeVjWIqYqaxCKSqnmQNaRtT2cokV4wtZfwBHSsImS1zAM1DHZCyH70T61hmPE1M\ni8uxk9CYmnDnkgJNgwsUCoi67t7743wgJzfHn3v8i+OLnw/p6n6+n8/nfM77w/dyXvf7PfdAqgpJ\nko7kB2ZdgCTp1GZQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktS1ctYFnAjnnHNO\nrVu3btZlSNKysmfPnj+sqrml5n0ogmLdunUMh8NZlyFJy0qSb00zz1tPkqQug0KS1GVQSJK6DApJ\nUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1\nGRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdU0VFEmuTPJckoUkWyeMr07yaBvf\nnWRd61+TZFeSt5JsW/SY/5bk60n2JflCkhWt/xNJvpzk+fb9B49/m5KkY7VkULQX8PuAjcAG4Pok\nGxZN2wK8XlUXAncDd7b+d4FbgZsnLP25qvpLwI8Bc8Dfav1bgZ1VtR7Y2Y4lSTMyzRXFpcBCVR2o\nqkPAI8CmRXM2ATta+zHg8iSpqrer6ilGgfE9qurN1lwJrAJqwlo7gGum3Ywk6cSbJijOA14cO36p\n9U2cU1WHgTeANUstnOQJ4BXgjxkFDMAnq+rbrf0HwCenqFGSdJLM9M3sqvoZ4FxgNfDTE8aL715p\nfI8kNyQZJhkePHjw5BYqSaexaYLiZeD8seO1rW/inCQrgbOAV6cpoKreBX6D797O+k6Sc9ta5zK6\n4pj0uO1VNaiqwdzc3DRPJUk6BtMExdPA+iQXJFkFXAfML5ozD2xu7WuBJ9vVwERJPjYWBiuBnwX2\nT1hrM6MQkSTNyMqlJlTV4SQ3Ak8AK4AHq2pfktuAYVXNAw8ADyVZAF5jFCYAJHkBOBNYleQa4ApG\nVxvzSVYzCqtdwBfaQ+4AvpRkC/At4HMnZKeSpGOSzi/+y8ZgMKjhcDjrMiRpWUmyp6oGS83zk9mS\npC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnq\nMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqWuqoEhyZZLnkiwk\n2TphfHWSR9v47iTrWv+aJLuSvJVk29j8M5I8nmR/kn1J7hgb+1R7zFeTPJPkquPfpiTpWC0ZFElW\nAPcBG4ENwPVJNiyatgV4vaouBO4G7mz97wK3AjdPWPquqroIuBi4LMnG1v9PgC9V1cXAdcC/Orot\nSZJOpGmuKC4FFqrqQFUdAh4BNi2aswnY0dqPAZcnSVW9XVVPMQqM91XVO1W1q7UPAXuBte8NA2e2\n9lnA7x/lniRJJ9A0QXEe8OLY8Uutb+KcqjoMvAGsmaaAJGcDVwM7W9fngZ9L8hLwX4F/MM06kqST\nY6ZvZidZCTwM3FtVB1r39cC/raq1wFXAQ0m+r84kNyQZJhkePHjwgytakk4z0wTFy8D5Y8drW9/E\nOe3F/yzg1SnW3g48X1X3jPVtAb4EUFX/B/gocM7iB1bV9qoaVNVgbm5uiqeSJB2LaYLiaWB9kguS\nrGL0BvP8ojnzwObWvhZ4sqqqt2iS2xkFyk2Lhn4PuLzN+RFGQeElgyTNyMqlJlTV4SQ3Ak8AK4AH\nq2pfktuAYVXNAw8wukW0ALzGKEwASPICozenVyW5BrgCeBO4BdgP7E0CsK2q7gd+Efhikn/I6I3t\nv71U6EiSTp58GF6DB4NBDYfDWZchSctKkj1VNVhqnp/MliR1GRSSpC6DQpLUZVBIkroMCklSl0Eh\nSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKk\nLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldUwVFkiuTPJdkIcnWCeOrkzzaxncnWdf61yTZleStJNvG\n5p+R5PEk+5PsS3LHovU+l+TZNvbvj2+LkqTjsWRQJFkB3AdsBDYA1yfZsGjaFuD1qroQuBu4s/W/\nC9wK3Dxh6buq6iLgYuCyJBvb860Hfgm4rKp+FLjpqHclSTphprmiuBRYqKoDVXUIeATYtGjOJmBH\naz8GXJ4kVfV2VT3FKDDeV1XvVNWu1j4E7AXWtuG/A9xXVa+38VeOYV+SpBNkmqA4D3hx7Pil1jdx\nTlUdBt4A1kxTQJKzgauBna3rh4EfTvK/k3wlyZVHeNwNSYZJhgcPHpzmqSRJx2Cmb2YnWQk8DNxb\nVQda90pgPfBXgeuBL7Yw+R5Vtb2qBlU1mJub+6BKlqTTzjRB8TJw/tjx2tY3cU578T8LeHWKtbcD\nz1fVPWN9LwHzVfWnVfW7wDcZBYckaQamCYqngfVJLkiyCrgOmF80Zx7Y3NrXAk9WVfUWTXI7o0BZ\n/Gb1f2Z0NUGScxjdijqAJGkmVi41oaoOJ7kReAJYATxYVfuS3AYMq2oeeAB4KMkC8BqjMAEgyQvA\nmcCqJNcAVwBvArcA+4G9SQC2VdX97XmuSPIs8GfAP66qaa5OJEknQZb4xX9ZGAwGNRwOZ12GJC0r\nSfZU1WCpeX4yW5LUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1LXkf8Ljw+yX\n/8s+nv39N2ddhiQdsw1/4Uz+2dU/elKfwysKSVLXaX1FcbJTWJI+DLyikCR1GRSSpC6DQpLUZVBI\nkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqSuqYIiyZVJnkuykGTrhPHVSR5t47uTrGv9a5Ls\nSvJWkm1j889I8niS/Un2Jbljwpp/M0klGRz79iRJx2vJoEiyArgP2AhsAK5PsmHRtC3A61V1IXA3\ncGfrfxe4Fbh5wtJ3VdVFwMXAZUk2jj3nx4FfAHYf3XYkSSfaNFcUlwILVXWgqg4BjwCbFs3ZBOxo\n7ceAy5Okqt6uqqcYBcb7quqdqtrV2oeAvcDasSn/nFHYfM/jJEkfvGmC4jzgxbHjl1rfxDlVdRh4\nA1gzTQFJzgauBna240uA86vq8WkeL0k6uWb6ZnaSlcDDwL1VdSDJDwC/CvziFI+9IckwyfDgwYMn\nu1RJOm1NExQvA+ePHa9tfRPntBf/s4BXp1h7O/B8Vd3Tjj8O/BjwP5O8AHwGmJ/0hnZVba+qQVUN\n5ubmpngqSdKxmCYongbWJ7kgySrgOmB+0Zx5YHNrXws8WVXVWzTJ7YwC5ab3+qrqjao6p6rWVdU6\n4CvAZ6tqONVuJEkn3JL/h7uqOpzkRuAJYAXwYFXtS3IbMKyqeeAB4KEkC8BrjMIEgHZlcCawKsk1\nwBXAm8AtwH5gbxKAbVV1/4ncnCTp+GWJX/yXhcFgUMOhFx2SdDSS7KmqJT+r5iezJUldBoUkqcug\nkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJ\nUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVLXVEGR5MokzyVZSLJ1wvjqJI+2\n8d1J1rX+NUl2JXkrybax+WckeTzJ/iT7ktwxNvaPkjyb5JkkO5P80PFvU5J0rJYMiiQrgPuAjcAG\n4PokGxZN2wK8XlUXAncDd7b+d4FbgZsnLH1XVV0EXAxclmRj6/8qMKiqHwceA37l6LYkSTqRprmi\nuBRYqKoDVXUIeATYtGjOJmBHaz8GXJ4kVfV2VT3FKDDeV1XvVNWu1j4E7AXWtuNdVfVOm/qV9/ol\nSbMxTVCcB7w4dvxS65s4p6oOA28Aa6YpIMnZwNXAzgnDW4DfnGYdSdLJsXKWT55kJfAwcG9VHVg0\n9nPAAPgrR3jsDcANAJ/61KdOcqWSdPqa5oriZeD8seO1rW/inPbifxbw6hRrbweer6p7xjuT/DXg\nFuCzVfUnkx5YVduralBVg7m5uSmeSpJ0LKYJiqeB9UkuSLIKuA6YXzRnHtjc2tcCT1ZV9RZNcjuj\nQLlpUf/FwL9hFBKvTFGfJOkkWvLWU1UdTnIj8ASwAniwqvYluQ0YVtU88ADwUJIF4DVGYQJAkheA\nM4FVSa4BrgDeZHTFsB/YmwRgW1XdD/wL4GPAr7f+36uqz56g/UqSjlKW+MV/WRgMBjUcDmddhiQt\nK0n2VNVgqXl+MluS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwK\nSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKlrqqBI\ncmWS55IsJNk6YXx1kkfb+O4k61r/miS7kryVZNvY/DOSPJ5kf5J9Se5Yai1J0mwsGRRJVgD3ARuB\nDcD1STYsmrYFeL2qLgTuBu5s/e8CtwI3T1j6rqq6CLgYuCzJxiXWkiTNwDRXFJcCC1V1oKoOAY8A\nmxbN2QTsaO3HgMuTpKrerqqnGAXG+6rqnara1dqHgL3A2t5aR7kvSdIJMk1QnAe8OHb8UuubOKeq\nDgNvAGumKSDJ2cDVwM7jXUuSdOLN9M3sJCuBh4F7q+rAUT72hiTDJMODBw+enAIlSVMFxcvA+WPH\na1vfxDntxf8s4NUp1t4OPF9V9xztWlW1vaoGVTWYm5ub4qkkScdimqB4Glif5IIkq4DrgPlFc+aB\nza19LfBkVVVv0SS3MwqBm453LUnSybNyqQlVdTjJjcATwArgwaral+Q2YFhV88ADwENJFoDXGIUJ\nAEleAM4EViW5BrgCeBO4BdgP7G3vVW+rqvt7a0mSPnj5MPyyPhgMajgczroMSVpWkuypqsFS8/xk\ntiSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBI\nkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSp\nK1U16xqOW5KDwLeO8eHnAH94AsuZJfdyanIvpyb3Aj9UVXNLTfpQBMXxSDKsqsGs6zgR3Mupyb2c\nmtzL9Lz1JEnqMigkSV0GBWyfdQEnkHs5NbmXU5N7mdJp/x6FJKnPKwpJUtdpHRRJrkzyXJKFJFtn\nXc/RSvJCkt9O8rUkw9b3iSRfTvJ8+/6Ds65zkiQPJnklyTfG+ibWnpF723l6Jskls6v8+x1hL59P\n8nI7N19LctXY2C+1vTyX5GdmU/X3S3J+kl1Jnk2yL8kvtP5ld146e1mO5+WjSX4rydfbXn659V+Q\nZHer+dEkq1r/6na80MbXHXcRVXVafgErgP8LfBpYBXwd2DDruo5yDy8A5yzq+xVga2tvBe6cdZ1H\nqP2ngEuAbyxVO3AV8JtAgM8Au2dd/xR7+Txw84S5G9rP2mrggvYzuGLWe2i1nQtc0tofB77Z6l12\n56Wzl+V4XgJ8rLU/Auxu/7y/BFzX+r8A/N3W/nvAF1r7OuDR463hdL6iuBRYqKoDVXUIeATYNOOa\nToRNwI7W3gFcM8Najqiq/hfw2qLuI9W+Cfh3NfIV4Owk534wlS7tCHs5kk3AI1X1J1X1u8ACo5/F\nmauqb1fV3tb+Y+B3gPNYhuels5cjOZXPS1XVW+3wI+2rgJ8GHmv9i8/Le+frMeDyJDmeGk7noDgP\neHHs+CX6P0inogL+e5I9SW5ofZ+sqm+39h8An5xNacfkSLUv13N1Y7sl8+DYLcBlsZd2u+JiRr+9\nLuvzsmgvsAzPS5IVSb4GvAJ8mdEVzx9V1eE2Zbze9/fSxt8A1hzP85/OQfFh8JNVdQmwEfj7SX5q\nfLBG157L8s/alnPtzb8G/iLwE8C3gX8523Kml+RjwH8AbqqqN8fHltt5mbCXZXlequrPquongLWM\nrnQu+iCf/3QOipeB88eO17a+ZaOqXm7fXwH+E6MfoO+8d/nfvr8yuwqP2pFqX3bnqqq+0/7l/n/A\nF/nubYxTei9JPsLohfXXquo/tu5leV4m7WW5npf3VNUfAbuAv8zoVt/KNjRe7/t7aeNnAa8ez/Oe\nzkHxNLC+/eXAKkZv+szPuKapJfnzST7+Xhu4AvgGoz1sbtM2A78xmwqPyZFqnwd+vv2VzWeAN8Zu\nhZySFt2r/xuMzg2M9nJd+8uUC4D1wG990PVN0u5jPwD8TlX96tjQsjsvR9rLMj0vc0nObu0/B/x1\nRu+57AKubdMWn5f3zte1wJPtSvDYzfod/Vl+MfqrjW8yut93y6zrOcraP83orzS+Dux7r35G9yJ3\nAs8D/wP4xKxrPUL9DzO69P9TRvdXtxypdkZ/9XFfO0+/DQxmXf8Ue3mo1fpM+xf33LH5t7S9PAds\nnHX9Y3X9JKPbSs8AX2tfVy3H89LZy3I8Lz8OfLXV/A3gn7b+TzMKswXg14HVrf+j7XihjX/6eGvw\nk9mSpK7T+daTJGkKBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSer6/+LiVVbyUA0iAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ4-W8W-WQbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}